{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGOY-FJ5q3MF",
        "outputId": "ed42f7c5-1dad-44a0-8b5b-ddd3a7cf80a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\kjjkjj\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "import requests\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nltk_utils.py\n",
        "import numpy as np\n",
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    split sentence into array of words/tokens\n",
        "    a token can be a word or punctuation character, or number\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "\n",
        "def stem(word):\n",
        "    \"\"\"\n",
        "    stemming = find the root form of the word\n",
        "    examples:\n",
        "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
        "    words = [stem(w) for w in words]\n",
        "    -> [\"organ\", \"organ\", \"organ\"]\n",
        "    \"\"\"\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self,intents_file):\n",
        "        with open(intents_file, 'r') as f:\n",
        "            intents = json.load(f)\n",
        "        self.intents = intents['intents']\n",
        "        self.all_words = []\n",
        "        self.tags = []\n",
        "        self.xy = []\n",
        "        for intent in self.intents:\n",
        "            tag = intent['tag']\n",
        "            self.tags.append(tag)\n",
        "            for pattern in intent['patterns']:\n",
        "                w = tokenize(pattern)\n",
        "                self.all_words.extend(w)\n",
        "                self.xy.append((w, tag))\n",
        "        self.ignore_words = ['?', '.', '!']\n",
        "        self.all_words = [stem(w) for w in self.all_words if w not in self.ignore_words]\n",
        "        self.all_words = sorted(set(self.all_words))\n",
        "        self.tags = sorted(set(self.tags))\n",
        "        self.n_classes = len(self.tags)\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = []\n",
        "        for (pattern_sentence, tag) in self.xy:\n",
        "            bag = bag_of_words(pattern_sentence, self.all_words)\n",
        "            label = self.tags.index(tag)\n",
        "            self.x_data.append(bag)\n",
        "            self.y_data.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_data[idx], self.y_data[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/500], Loss: 2.6477864735\n",
            "Epoch [20/500], Loss: 1.7428750974\n",
            "Epoch [30/500], Loss: 1.1636036034\n",
            "Epoch [40/500], Loss: 0.8151883941\n",
            "Epoch [50/500], Loss: 0.6143500478\n",
            "Epoch [60/500], Loss: 0.4778442298\n",
            "Epoch [70/500], Loss: 0.3860469501\n",
            "Epoch [80/500], Loss: 0.3168461173\n",
            "Epoch [90/500], Loss: 0.2636194138\n",
            "Epoch [100/500], Loss: 0.2361908162\n",
            "Epoch [110/500], Loss: 0.2051585512\n",
            "Epoch [120/500], Loss: 0.1770047836\n",
            "Epoch [130/500], Loss: 0.1579088687\n",
            "Epoch [140/500], Loss: 0.1441864513\n",
            "Epoch [150/500], Loss: 0.1343707059\n",
            "Epoch [160/500], Loss: 0.1161682269\n",
            "Epoch [170/500], Loss: 0.1111692761\n",
            "Epoch [180/500], Loss: 0.1025108124\n",
            "Epoch [190/500], Loss: 0.0958330432\n",
            "Epoch [200/500], Loss: 0.0941705985\n",
            "Epoch [210/500], Loss: 0.0835107295\n",
            "Epoch [220/500], Loss: 0.0780736200\n",
            "Epoch [230/500], Loss: 0.0743913496\n",
            "Epoch [240/500], Loss: 0.0715982203\n",
            "Epoch [250/500], Loss: 0.0670579222\n",
            "Epoch [260/500], Loss: 0.0685842690\n",
            "Epoch [270/500], Loss: 0.0628020431\n",
            "Epoch [280/500], Loss: 0.0634084471\n",
            "Epoch [290/500], Loss: 0.0571249260\n",
            "Epoch [300/500], Loss: 0.0529841473\n",
            "Epoch [310/500], Loss: 0.0537179767\n",
            "Epoch [320/500], Loss: 0.0524439485\n",
            "Epoch [330/500], Loss: 0.0488643026\n",
            "Epoch [340/500], Loss: 0.0426065705\n",
            "Epoch [350/500], Loss: 0.0487702795\n",
            "Epoch [360/500], Loss: 0.0481140337\n",
            "Epoch [370/500], Loss: 0.0433460105\n",
            "Epoch [380/500], Loss: 0.0434566190\n",
            "Epoch [390/500], Loss: 0.0407224222\n",
            "Epoch [400/500], Loss: 0.0372875219\n",
            "Epoch [410/500], Loss: 0.0397880256\n",
            "Epoch [420/500], Loss: 0.0370712476\n",
            "Epoch [430/500], Loss: 0.0385042116\n",
            "Epoch [440/500], Loss: 0.0412831613\n",
            "Epoch [450/500], Loss: 0.0330654742\n",
            "Epoch [460/500], Loss: 0.0343378485\n",
            "Epoch [470/500], Loss: 0.0354562121\n",
            "Epoch [480/500], Loss: 0.0345169524\n",
            "Epoch [490/500], Loss: 0.0356890599\n",
            "Epoch [500/500], Loss: 0.0351403502\n",
            "Finished training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# specify device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# create training dataset\n",
        "train_dataset = ChatDataset('intents.json')\n",
        "\n",
        "# define hyperparameters\n",
        "input_size = len(train_dataset.all_words)\n",
        "hidden_size = 40\n",
        "output_size = train_dataset.n_classes\n",
        "learning_rate = 0.0001\n",
        "batch_size = 40\n",
        "num_epochs = 500\n",
        "\n",
        "# create dataloader\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "# create neural network\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(words)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "    \n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.10f}')\n",
        "\n",
        "\n",
        "print('Finished training')\n",
        "\n",
        "# save the trained model\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": train_dataset.all_words,\n",
        "\"tags\": train_dataset.tags\n",
        "}\n",
        "\n",
        "FILE = \"./model.pth\"\n",
        "torch.save(data, FILE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, can you describe where you feel discomfort or pain? (type 'quit' to exit)\n",
            "I felt something wrong with my head.\n",
            "Health Bot: head ache\n",
            "here is some suggest : {'Description': 'A headache is a pain or discomfort that occurs in the head, scalp, or neck region. It can be classified into several types, including tension headaches, migraines, cluster headaches, and sinus headaches. Headaches can be caused by various factors, such as stress, anxiety, dehydration, lack of sleep, poor posture, eyestrain, and certain medical conditions.', 'SuggestionsText': 'Here are some suggestions for managing a headache', 'Suggestions': ['Drink plenty of water: Dehydration is a common cause of headaches, so make sure you drink enough water throughout the day.', 'Take a break: If you have been sitting at a desk or staring at a screen for an extended period, take a break and do some stretches.', 'Apply heat or cold: Applying heat or cold to the affected area can help relieve pain. Try using a hot compress or a cold pack.', 'Get enough sleep: Lack of sleep can trigger headaches, so make sure you are getting enough restful sleep.', 'Reduce stress: Stress is a common trigger of headaches. Consider practicing relaxation techniques such as meditation or deep breathing.']}\n"
          ]
        }
      ],
      "source": [
        "# chat.py\n",
        "import random\n",
        "import json\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "isFile = False\n",
        "FILE = \"./model.pth\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "ignore_tag= ['greeting','goodbye','thanks','noanswer','options','Identity','Request']\n",
        "\n",
        "\n",
        "with open('intents.json', 'r') as json_data:\n",
        "  intents = json.load(json_data)\n",
        "\n",
        "with open('suggestion.json', 'r') as suggestion:\n",
        "    suggestionData = json.load(suggestion)\n",
        "\n",
        "bot_name = \"Health Bot\"\n",
        "print(\"Hi, can you describe where you feel discomfort or pain? (type 'quit' to exit)\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\" or sentence == 'q':\n",
        "        break\n",
        "    print(sentence)\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "    \n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "\n",
        "    # print(prob)\n",
        "    if prob.item() > 0.80:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "                if(tag not in ignore_tag):\n",
        "                    print(f\"here is some suggest : {suggestionData[tag]}\")\n",
        "    elif prob.item() > 0.65:\n",
        "        if(tag not in ignore_tag):\n",
        "            for intent in intents['intents']:\n",
        "                if tag == intent[\"tag\"]:\n",
        "                    print(f\"{bot_name}: I don't quite understand your question, but it may be a {random.choice(intent['responses'])}\")\n",
        "                    \n",
        "        else:\n",
        "            print(f\"{bot_name}: I do not understand...\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
